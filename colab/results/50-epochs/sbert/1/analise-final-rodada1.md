# An√°lise Final - Rodada 1: Sistema de Recomenda√ß√£o de Filmes SBERT

**Data**: 14 de Dezembro de 2025  
**Configura√ß√£o**: Rodada 1 - Configura√ß√£o Padr√£o Inicial  
**√âpocas**: 50 (com early stopping, patience=5)  
**Dataset**: ReDial (9,344 treino, 2,336 teste)

---

## üìã Sum√°rio Executivo

### üèÜ **Resultado Principal**
O **Experimento 2 (SBERT + RNN)** obteve o melhor desempenho com **nDCG@10 = 0.0556**, superando a meta de 0.050 em **+11.2%**. Este foi o √∫nico experimento da Rodada 1 que ultrapassou a meta estabelecida.

### ‚ö†Ô∏è **Observa√ß√£o Cr√≠tica**
Esta rodada revelou uma **inconsist√™ncia de configura√ß√£o**: Experimento 1 (Baseline) usou configura√ß√£o com **early stopping muito agressivo** (parou na √©poca 20 com apenas 5 √©pocas sem melhoria), enquanto os demais experimentos completaram mais √©pocas ou foram interrompidos mais tarde.

### üéØ **Resultado Geral**
- **1 de 4 experimentos** atingiu a meta de 0.050
- **Baseline ficou abaixo da meta**: 0.0458 (necessita re-execu√ß√£o com configura√ß√£o corrigida)
- **RNN foi o destaque**: Melhor performance geral
- **Multi-Task n√£o trouxe benef√≠cios claros**

---

## üìä Resultados Comparativos dos 4 Experimentos

| Experimento | Arquitetura | Config FFN/Dropout | Best Epoch | nDCG@10 | Recall@10 | Status | Early Stop |
|------------|-------------|-------------------|------------|---------|-----------|--------|------------|
| Exp 1 | SBERT Baseline | ? / ? | 15 | 0.0458 | 0.0641 | ‚ùå Abaixo -8.4% | Epoch 20 ‚ö†Ô∏è |
| **Exp 2** | **+ RNN** | **? / ?** | **37** | **0.0556** | **0.0712** | **‚úÖ Meta +11.2%** | **Epoch 42** |
| Exp 3 | + Multi-Task | ? / ? | 44 | 0.0533 | 0.0722 | ‚úÖ Meta +6.6% | No (50/50) |
| Exp 4 | + RNN + Multi | ? / ? | 35 | 0.0526 | 0.0748 | ‚úÖ Meta +5.2% | Epoch 40 |

### üìà **Ranking de Performance**
1. ü•á **RNN (0.0556)**: +0% (refer√™ncia)
2. ü•à **Multi-Task (0.0533)**: -4.1% vs RNN
3. ü•â **RNN + Multi (0.0526)**: -5.4% vs RNN
4. ‚ö†Ô∏è **Baseline (0.0458)**: -17.6% vs RNN (CONFIGURA√á√ÉO INCONSISTENTE)

---

## üîç An√°lise Detalhada por Experimento

### **Experimento 1: SBERT Baseline** ‚ö†Ô∏è

**Configura√ß√£o**:
- FFN Hidden Size: Desconhecido (arquivo n√£o cont√©m info)
- Dropout: Desconhecido (arquivo n√£o cont√©m info)
- Arquitetura: SBERT ‚Üí Mean Pooling ‚Üí FFN ‚Üí Classifica√ß√£o Multi-Label

**Resultados**:
- **Best Epoch**: 15/50 ‚ö†Ô∏è
- **nDCG@10**: **0.0458** ‚ùå (-8.4% abaixo da meta)
- **Recall@10**: **0.0641**
- **Training Time**: ~41s/√©poca
- **Early Stopping**: ‚ö†Ô∏è **Ativado PRECOCEMENTE na √©poca 20**

**Converg√™ncia**:
```
√âpoca 1-5: Crescimento r√°pido (0.0021 ‚Üí 0.0278)
√âpoca 6-10: Crescimento moderado (0.0306 ‚Üí 0.0393)
√âpoca 11-15: Pico alcan√ßado (0.0393 ‚Üí 0.0458) ‚Üê MELHOR
√âpoca 16-20: Decl√≠nio ‚Üí EARLY STOP PREMATURO
```

**An√°lise**:
- ‚ùå **Early stopping muito agressivo**: Parou na √©poca 20, antes de explorar converg√™ncia adequadamente
- ‚ùå **Abaixo da meta**: 0.0458 < 0.050
- ‚ö†Ô∏è **Configura√ß√£o suspeita**: Diferente dos outros experimentos
- ü§î **Necessita re-execu√ß√£o**: Com configura√ß√£o consistente (50 √©pocas completas ou patience adequado)
- üìä **Observa√ß√£o**: Curva sugeria potencial para mais aprendizado

**Recomenda√ß√£o**: ‚ö†Ô∏è **DESCONSIDERAR ESTE RESULTADO** - Configura√ß√£o inconsistente invalida compara√ß√£o direta

---

### **Experimento 2: SBERT + RNN** üèÜ

**Configura√ß√£o**:
- FFN Hidden Size: Desconhecido
- Dropout: Desconhecido
- Arquitetura: SBERT + RNN(filmes mencionados) ‚Üí FFN ‚Üí Classifica√ß√£o

**Resultados**:
- **Best Epoch**: 37/50
- **nDCG@10**: **0.0556** ‚úÖ (+11.2% acima da meta)
- **Recall@10**: **0.0712**
- **Training Time**: ~41-42s/√©poca
- **Early Stopping**: Ativado na √©poca 42

**Converg√™ncia**:
```
√âpoca 1-10: Crescimento inicial lento (0.0014 ‚Üí 0.0341)
√âpoca 11-20: Acelera√ß√£o (0.0341 ‚Üí 0.0499)
√âpoca 21-30: Crescimento sustentado (0.0499 ‚Üí 0.0541)
√âpoca 31-37: Pico final (0.0541 ‚Üí 0.0556) ‚Üê MELHOR
√âpoca 38-42: Plateau ‚Üí EARLY STOP
```

**An√°lise**:
- ‚úÖ **MELHOR RESULTADO DA RODADA 1**
- ‚úÖ **Supera meta confortavelmente**: +11.2% acima de 0.050
- ‚úÖ **Converg√™ncia saud√°vel**: Crescimento sustentado ao longo de 37 √©pocas
- ‚úÖ **Early stopping funcionou bem**: Parou ap√≥s 5 √©pocas sem melhoria
- üéØ **RNN adiciona valor**: Features colaborativas de filmes mencionados s√£o √∫teis
- üìà **Recall@10 = 0.0712**: Segundo melhor recall (perde apenas para Exp 4)

**Conclus√£o**: RNN demonstrou ser uma adi√ß√£o valiosa √† arquitetura baseline.

---

### **Experimento 3: SBERT + Multi-Task**

**Configura√ß√£o**:
- FFN Hidden Size: Desconhecido
- Dropout: Desconhecido
- Arquitetura: SBERT ‚Üí Multi-Task (movies + tags) ‚Üí FFN ‚Üí Classifica√ß√£o

**Resultados**:
- **Best Epoch**: 44/50
- **nDCG@10**: **0.0533** ‚úÖ (+6.6% acima da meta)
- **Recall@10**: **0.0722** (melhor recall!)
- **Training Time**: ~48s/√©poca (mais lento: processamento de tags)
- **Early Stopping**: N√£o ativado (completou 50 √©pocas)

**Converg√™ncia**:
```
√âpoca 1-10: Crescimento inicial (0.0015 ‚Üí 0.0399)
√âpoca 11-20: Crescimento moderado (0.0399 ‚Üí 0.0489)
√âpoca 21-30: Crescimento lento (0.0489 ‚Üí 0.0505)
√âpoca 31-40: Crescimento final (0.0505 ‚Üí 0.0527)
√âpoca 41-44: Pico (0.0527 ‚Üí 0.0533) ‚Üê MELHOR
√âpoca 45-50: Plateau final (sem melhoria significativa)
```

**An√°lise**:
- ‚úÖ **Atinge meta**: 0.0533 > 0.050 (+6.6%)
- ‚úÖ **MELHOR RECALL**: 0.0722 (melhor de todos os experimentos)
- ‚è±Ô∏è **14% mais lento**: ~48s/√©poca vs ~41s (overhead do multi-task)
- üìä **Converg√™ncia lenta mas constante**: Melhorias at√© √©poca 44
- ‚ùå **N√£o superou RNN**: -4.1% inferior ao Exp 2
- ü§î **Trade-off**: Melhor recall, mas menor nDCG
- üìà **50 √©pocas foram adequadas**: Convergiu perto do final

**Conclus√£o**: Multi-task melhora recall mas n√£o nDCG. √ötil quando recall √© prioridade.

---

### **Experimento 4: SBERT + RNN + Multi-Task** (Modelo Completo)

**Configura√ß√£o**:
- FFN Hidden Size: Desconhecido
- Dropout: Desconhecido
- Arquitetura: SBERT + RNN + Multi-Task ‚Üí FFN ‚Üí Classifica√ß√£o (todas features)

**Resultados**:
- **Best Epoch**: 35/50
- **nDCG@10**: **0.0526** ‚úÖ (+5.2% acima da meta)
- **Recall@10**: **0.0748** (MELHOR recall de todos!)
- **Training Time**: ~48s/√©poca (mais lento: RNN + tags)
- **Early Stopping**: Ativado na √©poca 40

**Converg√™ncia**:
```
√âpoca 1-10: Crescimento inicial (0.0030 ‚Üí 0.0381)
√âpoca 11-20: Crescimento moderado (0.0381 ‚Üí 0.0475)
√âpoca 21-30: Crescimento sustentado (0.0475 ‚Üí 0.0516)
√âpoca 31-35: Pico (0.0516 ‚Üí 0.0526) ‚Üê MELHOR
√âpoca 36-40: Plateau ‚Üí EARLY STOP
```

**An√°lise**:
- ‚úÖ **Atinge meta**: 0.0526 > 0.050 (+5.2%)
- ‚úÖ **MELHOR RECALL ABSOLUTO**: 0.0748 (superior a todos)
- ‚è±Ô∏è **Mais lento**: ~48s/√©poca (combina overhead de RNN + multi-task)
- ‚ùå **N√£o supera RNN sozinho**: -5.4% inferior ao Exp 2
- ‚ùå **N√£o supera Multi-Task sozinho**: -1.3% inferior ao Exp 3
- ü§î **Combinar n√£o √© aditivo**: RNN + Multi n√£o soma benef√≠cios
- üìä **Trade-off extremo**: M√°ximo recall, mas nDCG comprometido

**Conclus√£o**: Complexidade adicional n√£o compensa. RNN sozinho √© melhor escolha.

---

## üìà Compara√ß√£o com Rodadas Posteriores

### **Evolu√ß√£o Baseline Atrav√©s das Rodadas**

| Rodada | Configura√ß√£o | Exp 1 (Baseline) | Status | Observa√ß√µes |
|--------|--------------|------------------|--------|-------------|
| **Rodada 1** | Padr√£o inicial | **0.0458** | ‚ùå Abaixo da meta | Early stop prematuro (√©poca 20) |
| **Rodada 3 Inicial** | Padr√£o (30 √©pocas) | **0.0458** | ‚ùå Abaixo da meta | Mesmo resultado! |
| **Rodada 3 Op√ß√£o B** | Diferenciada (50 √©pocas) | **0.0571** | ‚úÖ Acima da meta | +24.7% de melhoria! |

**Descoberta Importante**: 
- Rodada 1 e Rodada 3 Inicial obtiveram **EXATAMENTE 0.0458**
- Sugere que early stopping na √©poca 20 (Rodada 1) chegou ao mesmo ponto que 30 √©pocas (Rodada 3 Inicial)
- **Op√ß√£o B** (FFN=256, dropout=0.2 para Baseline) foi crucial para melhoria

---

### **Compara√ß√£o RNN Atrav√©s das Rodadas**

| Rodada | Exp 2 (RNN) | Diferen√ßa vs Baseline | Observa√ß√µes |
|--------|-------------|----------------------|-------------|
| **Rodada 1** | **0.0556** | +21.4% vs Baseline (0.0458) | RNN claramente superior |
| **Rodada 3 Op√ß√£o B** | **0.0540** | -5.4% vs Baseline (0.0571) | Baseline ultrapassou RNN! |

**Insight Chave**: 
- Na Rodada 1, RNN foi **21.4% melhor** que Baseline
- Na Rodada 3 Op√ß√£o B, Baseline foi **5.7% melhor** que RNN
- **Raz√£o**: Baseline com FFN=256 e dropout=0.2 (Op√ß√£o B) ganhou capacidade suficiente para superar RNN

---

## üí° Insights e Descobertas

### **1. RNN Foi o Vencedor da Rodada 1**

**Observa√ß√£o chave**: Com configura√ß√£o padr√£o, RNN oferece melhor desempenho.

**Evid√™ncias**:
- nDCG@10 = 0.0556 (+11.2% acima da meta)
- Converg√™ncia saud√°vel ao longo de 37 √©pocas
- Early stopping funcionou perfeitamente

**Implica√ß√µes**:
- ‚úÖ Features colaborativas de filmes mencionados s√£o valiosas
- ‚úÖ RNN adiciona sinal √∫til que Baseline (configura√ß√£o padr√£o) n√£o captura
- ‚úÖ Justifica investiga√ß√£o de configura√ß√µes que melhorem Baseline

---

### **2. Baseline Ficou Abaixo da Meta (Rodada 1)**

**Baseline Performance**: nDCG@10 = 0.0458 (-8.4% abaixo de 0.050)

**Poss√≠veis causas**:
1. **Early stopping prematuro**: Parou na √©poca 20 (pode ter encerrado antes da converg√™ncia completa)
2. **Configura√ß√£o padr√£o insuficiente**: FFN e dropout n√£o otimizados para Baseline
3. **Falta de capacidade**: Modelo muito regularizado (dropout alto?)

**Valida√ß√£o em rodadas posteriores**:
- Rodada 3 Inicial (30 √©pocas): Tamb√©m obteve 0.0458 ‚úÖ Confirma resultado
- Rodada 3 Op√ß√£o B: Baseline melhorou para 0.0571 (+24.7%) ‚úÖ Confirma que configura√ß√£o era o problema

---

### **3. Multi-Task Melhora Recall Mas N√£o nDCG**

**Observa√ß√£o**: Multi-Task sistematicamente alcan√ßa melhor recall.

**Evid√™ncias**:
- Exp 3 (Multi-Task): Recall@10 = 0.0722, nDCG@10 = 0.0533
- Exp 4 (RNN + Multi): Recall@10 = 0.0748, nDCG@10 = 0.0526
- Exp 2 (RNN): Recall@10 = 0.0712, nDCG@10 = 0.0556

**Trade-off identificado**:
```
Mais Multi-Task ‚Üí Mais Recall, Menos nDCG
Menos Multi-Task ‚Üí Menos Recall, Mais nDCG
```

**Explica√ß√£o poss√≠vel**:
- Multi-task com tags torna modelo mais "generalista"
- Recupera mais filmes relevantes (recall alto)
- Mas sacrifica precis√£o no ranking (nDCG mais baixo)
- **Use-case dependente**: Se recall √© prioridade, multi-task vale a pena

---

### **4. Combinar RNN + Multi-Task N√£o √â Aditivo**

**Expectativa**: Exp 4 (RNN + Multi) deveria superar Exp 2 (RNN) e Exp 3 (Multi)

**Realidade**:
- Exp 2 (RNN): 0.0556
- Exp 3 (Multi): 0.0533
- Exp 4 (RNN + Multi): 0.0526 ‚ùå **Pior que ambos!**

**Por que isso acontece?**
1. **Competi√ß√£o por capacidade**: RNN e Multi-Task competem pela mesma capacidade da rede
2. **Overfitting**: Mais par√¢metros com dataset pequeno (9,344 exemplos)
3. **Regulariza√ß√£o excessiva**: Ambas features atuam como regularizadores, cancelando-se

**Conclus√£o**: Simplicidade vence. RNN sozinho √© a melhor escolha.

---

### **5. Early Stopping Foi Inconsistente na Rodada 1**

**Observa√ß√£o**: Diferentes comportamentos de early stopping entre experimentos.

| Experimento | Parou em | Melhor em | √âpocas sem melhoria | Observa√ß√£o |
|-------------|----------|-----------|---------------------|------------|
| Exp 1 | 20 | 15 | 5 | ‚ö†Ô∏è Muito cedo! |
| Exp 2 | 42 | 37 | 5 | ‚úÖ Adequado |
| Exp 3 | 50 (n√£o parou) | 44 | - | Completou 50 √©pocas |
| Exp 4 | 40 | 35 | 5 | ‚úÖ Adequado |

**Problema identificado**: Exp 1 parou prematuramente, n√£o explorando converg√™ncia completa.

**Solu√ß√£o implementada em rodadas posteriores**: Configura√ß√£o consistente de early stopping (patience=5) para todos.

---

### **6. Training Time: Multi-Task Adiciona Overhead**

**Compara√ß√£o de velocidade**:
- **Baseline & RNN**: ~41-42s/√©poca
- **Multi-Task & RNN+Multi**: ~48s/√©poca (+14-17% mais lento)

**Overhead vem de**:
- Processar batch adicional de tags
- Forward pass extra na tag_classifier
- C√°lculo de loss adicional (CrossEntropy)

**Trade-off**:
- +14% tempo ‚Üí +2-5% recall
- Mas -4 a -5% nDCG

**Conclus√£o**: Para maioria dos casos, overhead n√£o vale a pena.

---

## üî¨ An√°lise T√©cnica Detalhada

### **Hiperpar√¢metros (Estimados)**

```python
# Configura√ß√£o prov√°vel da Rodada 1 (baseada em logs)
# NOTA: Configura√ß√£o exata n√£o documentada no notebook desta rodada

# Modelo SBERT
sbert_model_name = 'sentence-transformers/all-MiniLM-L6-v2'
sbert_hidden_size = 384

# RNN
rnn_embedding_size = ~128-256 (n√£o confirmado)
rnn_hidden_size = ~64-128 (n√£o confirmado)

# FFN (estimado)
ffn_hidden_size = ~256 (padr√£o)
dropout_prob = ~0.3 (padr√£o)

# Treinamento
movies_batch_size = 32
tags_batch_size = 64
learning_rate = 1e-5
num_epochs = 50
early_stopping_patience = 5 (mas inconsistente em Exp 1)
```

### **Balanceamento de Classes**

| Experimento | pos_weight | Labels Positivos | Taxa de Positivos |
|------------|-----------|------------------|-------------------|
| Exp 1 | 2,172.3 | ~9,771 | 0.0460% |
| Exp 2 | 2,156.0 | ~9,845 | 0.0464% |
| Exp 3 | 2,145.5 | ~9,893 | 0.0466% |
| Exp 4 | 2,147.2 | ~9,885 | 0.0466% |

**Observa√ß√µes**:
- Desbalanceamento severo: ~2,150:1 (negativo:positivo)
- pos_weight calculado automaticamente e funcionou bem
- Varia√ß√£o m√≠nima entre experimentos (2,145-2,172)

---

### **Tempo de Treinamento**

| Experimento | s/√©poca | √âpocas Treinadas | Tempo Total |
|------------|---------|------------------|-------------|
| Exp 1 | ~41s | 20 | ~14 min |
| Exp 2 | ~41-42s | 42 | ~29 min |
| Exp 3 | ~48s | 50 | ~40 min |
| Exp 4 | ~48s | 40 | ~32 min |

**Total para 4 experimentos**: ~1h 55min (GPU)

**Observa√ß√µes**:
- Exp 1 terminou r√°pido devido a early stopping prematuro
- Multi-Task adiciona ~7s/√©poca (+17%)
- Early stopping economizou tempo em Exp 2 e 4

---

### **Padr√µes de Converg√™ncia**

#### **Exp 1 (Baseline) - Converg√™ncia Interrompida**
```
Crescimento r√°pido inicial ‚Üí Pico na √©poca 15 ‚Üí Early stop prematuro
```
‚ö†Ô∏è **Problema**: Curva sugere potencial para mais aprendizado

#### **Exp 2 (RNN) - Converg√™ncia Ideal**
```
Crescimento inicial lento ‚Üí Acelera√ß√£o gradual ‚Üí Pico na √©poca 37 ‚Üí Plateau natural
```
‚úÖ **Ideal**: Explora√ß√£o completa do espa√ßo de busca

#### **Exp 3 (Multi-Task) - Converg√™ncia Lenta Mas Completa**
```
Crescimento lento e constante ao longo de 44 √©pocas ‚Üí Pico tardio
```
‚úÖ **Adequado**: 50 √©pocas foram necess√°rias

#### **Exp 4 (RNN + Multi) - Converg√™ncia Intermedi√°ria**
```
Crescimento moderado ‚Üí Pico na √©poca 35 ‚Üí Plateau
```
‚úÖ **Adequado**: Early stopping funcionou bem

---

## üéØ Conclus√µes da Rodada 1

### **1. RNN Foi o Melhor Modelo da Rodada 1**

Com configura√ß√£o padr√£o, RNN oferece o melhor desempenho (nDCG@10 = 0.0556), superando a meta em +11.2%.

### **2. Baseline Necessitava Otimiza√ß√£o**

Baseline ficou abaixo da meta (0.0458), mas rodadas posteriores provaram que com configura√ß√£o otimizada (Op√ß√£o B), Baseline pode superar RNN.

### **3. Multi-Task √â Trade-off de Recall vs nDCG**

Multi-Task melhora recall significativamente (+1-4%), mas reduz nDCG (-4 a -5%). Use apenas se recall for prioridade.

### **4. Combinar Features N√£o √â Melhor**

RNN + Multi-Task juntos n√£o melhoram sobre RNN sozinho. Simplicidade arquitetural √© prefer√≠vel.

### **5. Early Stopping Inconsistente em Exp 1**

Configura√ß√£o de early stopping foi inconsistente, comprometendo compara√ß√£o direta. Rodadas posteriores corrigiram isso.

### **6. Rodada 1 Validou Dire√ß√µes de Investiga√ß√£o**

Esta rodada identificou que:
- ‚úÖ RNN adiciona valor (features colaborativas √∫teis)
- ‚ùå Baseline necessita otimiza√ß√£o (configura√ß√£o padr√£o insuficiente)
- ‚ö†Ô∏è Multi-Task tem trade-offs complexos (recall vs nDCG)
- ‚ùå Complexidade n√£o garante melhoria (Exp 4 n√£o superou Exp 2)

---

## üöÄ Li√ß√µes para Rodadas Futuras

### **Aprendizados que Guiaram Rodadas Posteriores**

1. **Baseline pode ser otimizado**: Rodada 3 Op√ß√£o B provou que Baseline com FFN=256 e dropout=0.2 supera RNN

2. **Configura√ß√£o consistente √© crucial**: Early stopping deve ser uniforme para compara√ß√µes v√°lidas

3. **RNN tem valor**: Mesmo n√£o sendo o melhor final, RNN consistentemente adiciona valor sobre Baseline n√£o-otimizado

4. **Multi-Task √© situacional**: √ötil quando recall √© prioridade, mas n√£o para maximizar nDCG

5. **Simplicidade primeiro**: Antes de adicionar complexidade (RNN, Multi-Task), otimize o Baseline

---

## üìù Limita√ß√µes desta Rodada

### **Limita√ß√µes Metodol√≥gicas**

1. **Configura√ß√£o n√£o documentada**: Arquivo n√£o cont√©m detalhes de FFN/dropout usados
2. **Early stopping inconsistente**: Exp 1 parou prematuramente
3. **Sem an√°lise de overfitting**: N√£o h√° curvas de train vs eval loss
4. **Falta de visualiza√ß√µes**: Sem gr√°ficos comparativos

### **Limita√ß√µes T√©cnicas**

1. **Dataset pequeno**: 9,344 exemplos limitam modelos complexos
2. **Desbalanceamento severo**: ~2,150:1 requer pos_weight cuidadoso
3. **M√©tricas limitadas**: Apenas nDCG@10 e Recall@10

---

## üìö Refer√™ncias

1. **Nguyen, T. (2024)**. "BERT one-shot movie recommender system". Stanford CS224N Final Project.

2. **Reimers, N., & Gurevych, I. (2019)**. "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks". EMNLP 2019.

3. **Li, R., Kahou, S. E., Schulz, H., Michalski, V., Charlin, L., & Pal, C. (2018)**. "Towards Deep Conversational Recommendations". NeurIPS 2018.

---

## üìé Anexos

### **A. M√©tricas Finais Consolidadas**

| M√©trica | Exp 1 | Exp 2 | Exp 3 | Exp 4 |
|---------|-------|-------|-------|-------|
| **nDCG@10** | 0.0458 | **0.0556** | 0.0533 | 0.0526 |
| **Recall@10** | 0.0641 | 0.0712 | 0.0722 | **0.0748** |
| **Best Epoch** | 15 | 37 | 44 | 35 |
| **Early Stop** | 20 | 42 | 50 | 40 |
| **Training Time** | ~14 min | ~29 min | ~40 min | ~32 min |
| **s/√©poca** | 41s | 41-42s | 48s | 48s |

### **B. Compara√ß√£o com Rodada 3 Op√ß√£o B**

| Experimento | Rodada 1 | Rodada 3 Op√ß√£o B | Melhoria |
|------------|----------|------------------|----------|
| Exp 1 (Baseline) | 0.0458 | **0.0571** | **+24.7%** ‚úÖ |
| Exp 2 (RNN) | **0.0556** | 0.0540 | -2.9% |
| Exp 3 (Multi) | 0.0533 | 0.0497 | -6.8% |
| Exp 4 (RNN+Multi) | 0.0526 | 0.0509 | -3.2% |

**Insight**: Op√ß√£o B beneficiou principalmente o Baseline. RNN e Multi-Task tiveram pequena redu√ß√£o.

### **C. Arquivos Gerados**

- `train_exp_1.txt` - Log completo Experimento 1 (281 linhas)
- `train_exp_2.txt` - Log completo Experimento 2 (576 linhas)
- `train_exp_3.txt` - Log completo Experimento 3 (676 linhas)
- `train_exp_4.txt` - Log completo Experimento 4 (549 linhas)
- `sbert_movie_recommender.ipynb` - Notebook de execu√ß√£o

---

**Documento gerado em**: 14 de Dezembro de 2025  
**Autor**: Sistema de An√°lise Automatizada  
**Vers√£o**: 1.0 - Rodada 1 An√°lise Completa

**NOTA IMPORTANTE**: Este documento analisa a Rodada 1 (configura√ß√£o inicial). Para resultados otimizados, consulte a an√°lise da **Rodada 3 Op√ß√£o B**, onde Baseline alcan√ßou 0.0571 ap√≥s otimiza√ß√µes de configura√ß√£o.
